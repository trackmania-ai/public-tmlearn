{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c49dd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# |default_exp neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79585a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "import logging\n",
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "import timm\n",
    "import torch\n",
    "from fastai.layers import ConvLayer, LinBnDrop, ResizeBatch, SigmoidRange, Identity\n",
    "from fastai.tabular.model import TabularModel\n",
    "from fastai.vision.models.xresnet import *\n",
    "from fastcore.basics import store_attr\n",
    "from fastcore.foundation import L\n",
    "from torch import nn\n",
    "from torch.distributions.categorical import Categorical\n",
    "from torch.distributions.normal import Normal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21695e67-aded-4cf7-8249-fdec9112ddb1",
   "metadata": {},
   "source": [
    "# Neural\n",
    "> Neural networks models used by the AI to learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb5fc38-7cef-4443-a93d-34df67b37b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "def init_weights(m):\n",
    "    if isinstance(m, (nn.Conv1d, nn.Conv2d, nn.Conv3d, nn.Linear)): nn.init.kaiming_normal_(m.weight)\n",
    "\n",
    "class StateCatNet(nn.Module):\n",
    "    def __init__(self, **module_mapping):\n",
    "        super().__init__()\n",
    "        self.output_dim = 0\n",
    "        for name, module in OrderedDict(sorted(module_mapping.items())).items():\n",
    "            if not isinstance(module, nn.Module):\n",
    "                module = module()\n",
    "            self.add_module(name, module)\n",
    "            self.output_dim += module.output_dim\n",
    "\n",
    "    def forward(self, state):\n",
    "        if isinstance(state, dict):\n",
    "            state = [state]\n",
    "        outputs = [\n",
    "            module(torch.stack([s[name] for s in state]))\n",
    "            for name, module in self.named_children()\n",
    "        ]\n",
    "        return torch.cat(\n",
    "            outputs,\n",
    "            dim=1,\n",
    "        )\n",
    "\n",
    "\n",
    "class Flatten(nn.Flatten):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.output_dim = np.prod(input_dim).item()\n",
    "\n",
    "\n",
    "def truncated_timm_model(name, nb_trunc=1, pretrained=True):\n",
    "    model = timm.create_model(name, pretrained=pretrained)\n",
    "    return nn.Sequential(*list(model.children())[:-nb_trunc])\n",
    "\n",
    "class TimmModel(nn.Module):\n",
    "    def __init__(self, name, input_dim, positional=False, pretrained=True, global_pool=\"catavgmax\"):\n",
    "        super().__init__()\n",
    "        c, h, w = input_dim\n",
    "        self.positional = positional\n",
    "        if self.positional:\n",
    "            c += 2\n",
    "            vertical = torch.tile(torch.linspace(0,1,h).unsqueeze(1), (1,w))\n",
    "            horizontal = torch.tile(torch.linspace(0,1,w).unsqueeze(0), (h,1))\n",
    "            positional_channels = torch.stack((vertical,horizontal)).unsqueeze(0)\n",
    "            self.register_buffer(\"positional_channels\", positional_channels)\n",
    "        self.raw_model = timm.create_model(\n",
    "            name,\n",
    "            in_chans=c,\n",
    "            pretrained=pretrained,\n",
    "            num_classes=0,\n",
    "            global_pool=global_pool\n",
    "        )\n",
    "        self.output_dim = self.raw_model(torch.rand(1, c, h, w)).shape[1]\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.positional:\n",
    "            x = torch.cat((\n",
    "                torch.tile(self.positional_channels, (x.shape[0], 1, 1, 1)),\n",
    "                x\n",
    "            ), dim=1)\n",
    "        return self.raw_model(x)\n",
    "        \n",
    "\n",
    "class VisualNet(nn.Sequential):\n",
    "    def __init__(self, model, input_dim, hidden=16):\n",
    "        if not isinstance(model, nn.Module):\n",
    "            model = model()\n",
    "        t = model(torch.rand(1, *input_dim))\n",
    "        _, c, h, w = t.shape\n",
    "        resize = ResizeBatch(c*h, w)\n",
    "        conv1 = ConvLayer(c*h, hidden, ks=1, ndim=1)\n",
    "        conv2 = ConvLayer(hidden, hidden, ks=5, stride=3, ndim=1)\n",
    "        flat = nn.Flatten()\n",
    "        self.output_dim = flat(conv2(conv1(resize(t)))).shape[1]\n",
    "        super().__init__(model,resize,conv1,conv2,flat)\n",
    "\n",
    "\n",
    "class FlatLinearNet(nn.Sequential):\n",
    "    def __init__(self, input_dim, hidden=64, output_dim=32, p=0., act=nn.ReLU(inplace=True)):\n",
    "        self.output_dim = output_dim\n",
    "        layers_dim = L(input_dim).product() + L(hidden) + output_dim\n",
    "        layers = L(nn.Flatten())\n",
    "        for inp, out in zip(layers_dim, layers_dim[1:-1]):\n",
    "            layers.append(LinBnDrop(inp, out, bn=False, p=p, act=act))\n",
    "        layers.append(LinBnDrop(layers_dim[-2], layers_dim[-1], bn=True, p=0.))\n",
    "        super().__init__(*layers)\n",
    "\n",
    "class Conv1dFlat(nn.Sequential):\n",
    "    def __init__(self, input_dim, hidden=16):\n",
    "        flatten = Flatten(L(hidden) + input_dim[1:])\n",
    "        self.output_dim = flatten.output_dim\n",
    "        super().__init__(nn.Conv1d(input_dim[0], hidden, 1), nn.ReLU(), flatten)\n",
    "\n",
    "\n",
    "class DuelingNet(nn.Module):\n",
    "    def __init__(self, model, output_dim, hidden=256, p=0.0):\n",
    "        super().__init__()\n",
    "        store_attr()\n",
    "        if not isinstance(self.model, nn.Module):\n",
    "            self.model = self.model()\n",
    "        self.value_stream = FlatLinearNet(self.model.output_dim, hidden, 1, p)\n",
    "        self.advantage_stream = FlatLinearNet(self.model.output_dim, hidden, output_dim, p)\n",
    "\n",
    "    def forward(self, state):\n",
    "        features = self.model(state)\n",
    "        values = self.value_stream(features)\n",
    "        advantages = self.advantage_stream(features)\n",
    "        return values + (advantages - advantages.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898b26f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# |hide\n",
    "# |eval: false\n",
    "from nbdev.doclinks import nbdev_export\n",
    "\n",
    "nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
