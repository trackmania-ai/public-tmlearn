{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c4ecb9-7059-4e66-bbcf-a44731dbd423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# |default_exp replay_buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b1e695-6b52-4247-b5fa-99c94c5152b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "import logging\n",
    "from functools import cached_property\n",
    "from queue import Empty, Full\n",
    "from time import time\n",
    "\n",
    "import torch\n",
    "import torch.multiprocessing as mp\n",
    "from fastcore.basics import store_attr\n",
    "from fastcore.foundation import L\n",
    "from torch.utils.data import WeightedRandomSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5aca8b-d203-4f4f-a453-9430a065ad54",
   "metadata": {},
   "source": [
    "# Replay Buffer\n",
    "> Buffer that save past experience and allow to sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b693523-8721-4b09-a6a2-3ff5df951419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "class PrioritizedReplayBuffer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        capacity,\n",
    "        queue_capacity=128,\n",
    "        prob_alpha=0.5,\n",
    "        e=1e-5,\n",
    "        beta=1.0,\n",
    "        beta_increment=1e-5,\n",
    "        device=\"cpu\",\n",
    "    ):\n",
    "        store_attr()\n",
    "        self.experience_queue = mp.Queue(queue_capacity)\n",
    "\n",
    "    def push(self, *args):\n",
    "        try:\n",
    "            self.experience_queue.put(args, False)\n",
    "        except Full:\n",
    "            logging.warning(\"Replay buffer queue is full\")\n",
    "\n",
    "    @cached_property\n",
    "    def buffer(self):\n",
    "        return L()\n",
    "\n",
    "    @cached_property\n",
    "    def pos(self):\n",
    "        return 0\n",
    "\n",
    "    @cached_property\n",
    "    def priorities(self):\n",
    "        return torch.zeros(\n",
    "            (self.capacity,), dtype=torch.float, device=self.device, requires_grad=False\n",
    "        )\n",
    "\n",
    "    @cached_property\n",
    "    def last_insert_time(self):\n",
    "        return time()\n",
    "\n",
    "    def empty_queue(self):\n",
    "        try:\n",
    "            while True:\n",
    "                self._push(*self.experience_queue.get(False))\n",
    "                self.last_insert_time = time()\n",
    "        except Empty:\n",
    "            pass\n",
    "\n",
    "    def _push(self, state, next_state, action, reward, done):\n",
    "        max_prio = self.priorities.max() if self.buffer else 1.0\n",
    "\n",
    "        if len(self.buffer) < self.capacity:\n",
    "            self.buffer.append((state, next_state, action, reward, done))\n",
    "        else:\n",
    "            self.buffer[self.pos] = (state, next_state, action, reward, done)\n",
    "\n",
    "        self.priorities[self.pos] = max_prio\n",
    "        self.pos = (self.pos + 1) % self.capacity\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        self.beta = min(1.0, self.beta + self.beta_increment)\n",
    "\n",
    "        prios = self.priorities[: len(self)]\n",
    "        indices = L(WeightedRandomSampler(prios, batch_size, replacement=False))\n",
    "        samples = self.buffer[indices]\n",
    "\n",
    "        total = len(self.buffer)\n",
    "        weights = (total * (prios / prios.sum())[indices]) ** (-self.beta)\n",
    "        weights /= weights.max()\n",
    "\n",
    "        return samples, indices, weights\n",
    "\n",
    "    def update_priorities(self, indices, errors):\n",
    "        p = torch.nan_to_num(errors, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        p = torch.nn.functional.relu(p)\n",
    "        if not torch.equal(p, errors):\n",
    "            logging.warn(\n",
    "                \"Received invalid priority, either `inf`, `nan` or element < 0\"\n",
    "            )\n",
    "        self.priorities[indices] = (p + self.e) ** self.prob_alpha\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b2dea0-5b0d-4d88-b249-df7ac1421e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# |hide\n",
    "# |eval: false\n",
    "from nbdev.doclinks import nbdev_export\n",
    "\n",
    "nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4994943a-0042-4015-9ad3-6aad68fcfb20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
