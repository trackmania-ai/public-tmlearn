{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baba7288-dd75-4a93-b54e-e4ee29ec825e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# |default_exp training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6471d5e7-0f6d-40ba-8599-65ed99176f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "import json\n",
    "import logging\n",
    "from collections.abc import Iterator\n",
    "from functools import partial\n",
    "from itertools import cycle\n",
    "from pathlib import Path\n",
    "from threading import Thread\n",
    "from time import sleep, time\n",
    "\n",
    "import torch\n",
    "import wandb\n",
    "from fastcore.basics import store_attr\n",
    "from fastcore.foundation import L, Self\n",
    "from human_id import generate_id\n",
    "from torch.multiprocessing import Manager, Queue\n",
    "\n",
    "from tmenv.gbx import map_from_uid\n",
    "from tmlearn.callback import Callback, Callbackable\n",
    "from tmlearn.collector import (\n",
    "    ActionPublisherCallback,\n",
    "    CollectorWorker,\n",
    "    SessionPublisherCallback,\n",
    "    StepPublisherCallback,\n",
    "    WandbCollectorCallback,\n",
    "    EigenCamPublisherCallback,\n",
    ")\n",
    "from tmlearn.net import WebsocketServer\n",
    "from tmlearn.utils import Timer, format_date, format_duration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33d518b-86c4-4de3-bab9-7673a5ff3158",
   "metadata": {},
   "source": [
    "# Training\n",
    "> Manager coordinating a training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cfa885-49b4-4db0-abf1-28c198e547b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "class Training(Callbackable):\n",
    "    def __init__(\n",
    "        self,\n",
    "        map_scheduler,\n",
    "        envs,\n",
    "        agent,\n",
    "        replay_buffer,\n",
    "        session_scheduler,\n",
    "        collector_cbs=[],\n",
    "        training_cbs=[],\n",
    "        batch_size=32,\n",
    "        burnin=1024,\n",
    "        online=True,  # Activate websocket and wandb logging\n",
    "        log_every=2,\n",
    "        ws_port=2013,\n",
    "        wandb_project=\"tmaifoo\",\n",
    "        wandb_entity=\"trackmania-ai\",\n",
    "        wandb_load_group=None,\n",
    "        wandb_load_agent=\"agent-latest.pth\",\n",
    "    ):\n",
    "        super().__init__(training_cbs)\n",
    "        store_attr(but=\"training_cbs\")\n",
    "\n",
    "        if self.online:\n",
    "            self.wandb_api = wandb.Api()\n",
    "            self.ws_server = WebsocketServer(port=self.ws_port)\n",
    "            self.init_wandb_run()\n",
    "            self.add_cb(WandbSaveAgentSlidingCallback)\n",
    "            self.add_cb(WandbSaveAgentPersistentCallback)\n",
    "            self.load_state_dict(json.loads(self.wandb_run.summary.get(\"state_dict\")))\n",
    "            self.log_timer = Timer(self.log_every)\n",
    "\n",
    "        self.map_scheduler.start()\n",
    "        self.collectors_worker = L(envs).map(self.build_worker)\n",
    "        self.collectors_worker.map(Self.start())\n",
    "\n",
    "    def fit(self):\n",
    "        self(\"before_fit\")\n",
    "        while len(self.replay_buffer) < self.burnin:\n",
    "            sleep(0.1)\n",
    "            self.replay_buffer.empty_queue()\n",
    "            if self.online:\n",
    "                self.wandb_run.summary[\"state_dict\"] = json.dumps(self.state_dict())\n",
    "        logging.info(\"Burnin completed. Time to learn !\")\n",
    "        self(\"after_burnin\")\n",
    "        while True:\n",
    "            self.replay_buffer.empty_queue()\n",
    "            self(\"before_fit_one_batch\")\n",
    "            batch, indices, weights = self.replay_buffer.sample(self.batch_size)\n",
    "            errors, metrics = self.agent.fit_one_batch(batch, weights)\n",
    "            self(\"after_fit_one_batch\")\n",
    "            self.replay_buffer.update_priorities(indices, errors)\n",
    "            if self.online and self.log_timer():\n",
    "                self.wandb_run.log(metrics)\n",
    "                self.wandb_run.summary[\"state_dict\"] = json.dumps(self.state_dict())\n",
    "                self.log_timer.reinit()\n",
    "\n",
    "    def init_wandb_run(self):\n",
    "        if self.wandb_load_group is not None:\n",
    "            training_runs = self.training_runs(self.wandb_load_group)\n",
    "            assert (\n",
    "                len(training_runs) == 1\n",
    "            ), f\"Found {len(training_runs)} training run(s) found, must be exactly one\"\n",
    "            self.wandb_run = wandb.init(\n",
    "                project=self.wandb_project,\n",
    "                entity=self.wandb_entity,\n",
    "                group=self.wandb_load_group,\n",
    "                id=training_runs[0].id,\n",
    "                resume=\"must\",\n",
    "            )\n",
    "        else:\n",
    "            while self.training_runs(group := generate_id(word_count=3)):\n",
    "                pass\n",
    "            self.wandb_run = wandb.init(\n",
    "                project=self.wandb_project,\n",
    "                entity=self.wandb_entity,\n",
    "                group=group,\n",
    "                name=f\"Training {group}\",\n",
    "                job_type=\"training\",\n",
    "                tags=[\"training\"] + self.agent.tags,\n",
    "            )\n",
    "            self.wandb_run.summary[\"state_dict\"] = json.dumps(self.state_dict())\n",
    "        self.save_dir = Path(self.wandb_run.dir) / \"agent\"\n",
    "        logging.debug(f\"Saving agents locally to {self.save_dir}\")\n",
    "        self.save_dir.mkdir(parents=True, exist_ok=True)\n",
    "        if self.wandb_load_group is not None and self.wandb_load_agent is not None:\n",
    "            self.load_agent(self.wandb_load_agent)\n",
    "            self.save_agent(\"last-loaded\", overwrite_latest=False)\n",
    "\n",
    "    def save_agent(self, raw_name, state_dict=None, overwrite_latest=True):\n",
    "        if state_dict is None:\n",
    "            state_dict = self.agent.state_dict()\n",
    "        torch.save(\n",
    "            state_dict,\n",
    "            self.save_dir / f\"agent-{raw_name}.pth\",\n",
    "        )\n",
    "        if overwrite_latest:\n",
    "            torch.save(\n",
    "                state_dict,\n",
    "                self.save_dir / f\"agent-latest.pth\",\n",
    "            )\n",
    "        self.wandb_run.save(\"agent/*.pth\", policy=\"now\")\n",
    "\n",
    "    def load_agent(self, file, run_path=None):\n",
    "        if run_path is None:\n",
    "            run_path = self.wandb_run.path\n",
    "        state_dict = torch.load(wandb.restore(f\"agent/{file}\", run_path=run_path).name)\n",
    "        self.agent.load_state_dict(state_dict)\n",
    "\n",
    "    @property\n",
    "    def wandb_path(self):\n",
    "        return f\"{self.wandb_entity}/{self.wandb_project}\"\n",
    "\n",
    "    def training_runs(self, group):\n",
    "        filters = dict(group=group, tags=\"training\")\n",
    "        return L(self.wandb_api.runs(self.wandb_path, filters))\n",
    "\n",
    "    def build_worker(self, env):\n",
    "        online_cbs = []\n",
    "        if self.online:\n",
    "            online_cbs += [\n",
    "                partial(\n",
    "                    WandbCollectorCallback,\n",
    "                    project=self.wandb_project,\n",
    "                    entity=self.wandb_entity,\n",
    "                    group=self.wandb_run.group,\n",
    "                ),\n",
    "                partial(\n",
    "                    ActionPublisherCallback,\n",
    "                    self.ws_server.add_publisher(f\"{env.name}-action\"),\n",
    "                ),\n",
    "                partial(\n",
    "                    StepPublisherCallback,\n",
    "                    self.ws_server.add_publisher(f\"{env.name}-step\"),\n",
    "                ),\n",
    "                partial(\n",
    "                    SessionPublisherCallback,\n",
    "                    self.ws_server.add_publisher(f\"{env.name}-session\"),\n",
    "                ),\n",
    "                # partial(\n",
    "                #     EigenCamPublisherCallback,\n",
    "                #     self.ws_server.add_publisher(f\"{env.name}-cam\"),\n",
    "                # ),\n",
    "            ]\n",
    "\n",
    "        return CollectorWorker(\n",
    "            env,\n",
    "            self.collector_cbs + online_cbs,\n",
    "            self.agent,\n",
    "            self.replay_buffer,\n",
    "            self.session_scheduler,\n",
    "            self.map_scheduler.next_queue,\n",
    "            self.map_scheduler.done_queue,\n",
    "        )\n",
    "\n",
    "    def state_dict(self):\n",
    "        return dict(\n",
    "            map_scheduler=self.map_scheduler.state_dict(), cbs=self.cbs_state_dict()\n",
    "        )\n",
    "\n",
    "    def load_state_dict(self, state_dict):\n",
    "        self.map_scheduler.load_state_dict(state_dict[\"map_scheduler\"])\n",
    "        if \"cbs\" in state_dict:\n",
    "            self.load_cbs_state_dict(state_dict[\"cbs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3474e6-6278-4ef6-9f18-52646c26df0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "class MapScheduler:\n",
    "    def __init__(self, maps_uid):\n",
    "        assert 0 < len(maps_uid)\n",
    "        self.maps_uid = maps_uid\n",
    "        self.next_maps = L()  # maps to be queued\n",
    "        self.queued_maps = L()  # queued maps not done yet\n",
    "        self.next_queue = Queue(1)\n",
    "        self.done_queue = Queue()\n",
    "\n",
    "    def start(self):\n",
    "        Thread(target=self.next_maps_target).start()\n",
    "        Thread(target=self.done_maps_target).start()\n",
    "\n",
    "    def next_maps_target(self):\n",
    "        while True:\n",
    "            if not self.next_maps:\n",
    "                self.next_maps.extend(self.maps_uid)\n",
    "            map_uid = self.next_maps.pop(0)\n",
    "            if map_uid in self.queued_maps:\n",
    "                logging.warning(\n",
    "                    f\"Skipping map uid {map_uid}, map is already being played\"\n",
    "                )\n",
    "                continue\n",
    "            self.queued_maps.append(map_uid)\n",
    "            self.next_queue.put(map_uid)\n",
    "\n",
    "    def done_maps_target(self):\n",
    "        while True:\n",
    "            self.queued_maps.remove(self.done_queue.get())\n",
    "\n",
    "    def state_dict(self):\n",
    "        return dict(next_maps=list(self.next_maps), queued_maps=list(self.queued_maps))\n",
    "\n",
    "    def load_state_dict(self, state_dict):\n",
    "        self.next_maps = L(state_dict[\"queued_maps\"] + state_dict[\"next_maps\"])\n",
    "\n",
    "class OneMapScheduler:\n",
    "    def __init__(self, map_uid):\n",
    "        self.map_uid = map_uid\n",
    "        self.next_queue = Queue(100)\n",
    "        while not self.next_queue.full():\n",
    "            self.next_queue.put(map_uid)\n",
    "        self.done_queue = Queue()\n",
    "\n",
    "    def start(self):\n",
    "        pass\n",
    "\n",
    "    def state_dict(self):\n",
    "        pass\n",
    "\n",
    "    def load_state_dict(self, state_dict):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3296eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "class ExperienceTimeoutException(Exception):\n",
    "    pass\n",
    "\n",
    "\n",
    "class ExperienceTimeoutCallback(Callback):\n",
    "    def __init__(self, timeout=5 * 60):\n",
    "        store_attr()\n",
    "\n",
    "    def before_fit_one_batch(self):\n",
    "        if self.timeout < time() - self.parent.replay_buffer.last_insert_time:\n",
    "            self.parent.collectors_worker.map(Self.kill())\n",
    "            raise ExperienceTimeoutException(\n",
    "                f\"Replay buffer received no new experiences for more than {format_duration(self.timeout)}.\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6499f177-0252-4427-b6be-fc001c630982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "class LrSchedulerCallback(Callback):\n",
    "    def __init__(self, scheduler, max_time):\n",
    "        store_attr()\n",
    "        self.offset = 0\n",
    "        self.start_time = time()\n",
    "\n",
    "    def before_fit(self):\n",
    "        self.start_time = time() - self.offset\n",
    "\n",
    "    def before_fit_one_batch(self):\n",
    "        lr = self.scheduler(min(1, (time() - self.start_time) / self.max_time))\n",
    "        self.parent.agent.set_lr(lr)\n",
    "\n",
    "    def state_dict(self):\n",
    "        return dict(offset=time() - self.start_time)\n",
    "\n",
    "    def load_state_dict(self, state_dict):\n",
    "        self.offset = state_dict[\"offset\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4c72a5-50f2-4b32-8273-8471c7e95d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "class WandbSaveAgentSlidingCallback(Callback):\n",
    "    def __init__(self, every=3600, nb_save=25):\n",
    "        store_attr()\n",
    "        self.timer = Timer(every)\n",
    "        self.agents = []\n",
    "\n",
    "    def before_fit_one_batch(self):\n",
    "        if self.timer():\n",
    "            self._save()\n",
    "            self.timer.reinit()\n",
    "\n",
    "    def _save(self):\n",
    "        self.agents.insert(0, self.parent.agent.state_dict())\n",
    "        self.agents = self.agents[: self.nb_save]\n",
    "        for index, state_dict in enumerate(self.agents):\n",
    "            self.parent.save_agent(\n",
    "                format_duration(index * self.every), state_dict, index == 0\n",
    "            )\n",
    "\n",
    "\n",
    "class WandbSaveAgentPersistentCallback(Callback):\n",
    "    def __init__(self, every=48 * 3600):\n",
    "        store_attr()\n",
    "        self.offset = 0\n",
    "        self.start_time = time()\n",
    "\n",
    "    def before_fit(self):\n",
    "        self.start_time = time() - self.offset\n",
    "        self.timer = Timer(self.every - (self.offset % self.every))\n",
    "\n",
    "    def before_fit_one_batch(self):\n",
    "        if self.timer():\n",
    "            self.parent.save_agent(format_date(\"%Y-%m-%d_%H-%M\"))\n",
    "            self.timer = Timer(self.every)\n",
    "\n",
    "    def state_dict(self):\n",
    "        return dict(offset=time() - self.start_time)\n",
    "\n",
    "    def load_state_dict(self, state_dict):\n",
    "        self.offset = state_dict[\"offset\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7d48d6-fcce-4e0e-917e-5361dd61b5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# |hide\n",
    "# |eval: false\n",
    "from nbdev.doclinks import nbdev_export\n",
    "\n",
    "nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1487cb69-b265-4c54-87ae-5d12371957db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
